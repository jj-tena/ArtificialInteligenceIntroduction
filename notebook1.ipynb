{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## TAREA 1 A"
      ],
      "metadata": {
        "id": "fQPh7E22nkM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Selección de Dataset\n",
        "\n",
        "El dataset seleccionado se trata de Heart Disease Health Indicators Dataset: https://www.kaggle.com/datasets/alexteboul/heart-disease-health-indicators-dataset/discussion/284985\n",
        "\n",
        "Este dataset contiene la información de 253680 sujetos de estudio, reflejando una serie de características que han sido observadas en pacientes con el fin de conocer su utilidad como predictores del riesgo de infarto de miocardio en el sujeto."
      ],
      "metadata": {
        "id": "2iPvZuiLf-oR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/heart_disease_health_indicators.csv'\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "BXo7xEjVgmO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Análisis Preliminar\n",
        "\n",
        "Para cada paciente se estudian las siguientes características:\n",
        "\n",
        "*   HeartDiseaseorAttack : indica si el paciente ha sufrido un infarto cardiaco (1) o si no lo ha padecido (0).\n",
        "*   HighBP : indica si un profesional sanitario ha informado a la persona de que padece hipertensión.\n",
        "*   HighChol : indica si un profesional sanitario ha informado a la persona de que tiene el colesterol alto.\n",
        "*   CholCheck : Control del colesterol, si la persona se ha controlado los niveles de colesterol en los últimos 5 años.\n",
        "*   IMC : indice de masa corporal, calculado dividiendo el peso de la persona (en kilogramos) por el cuadrado de su estatura (en metros).\n",
        "*   Smoker : indica si la persona ha fumado al menos 100 cigarrillos.\n",
        "*   Stroke: indica si la persona tiene antecedentes de accidente cerebrovascular.\n",
        "*   Diabetes : indica si la persona tiene antecedentes de diabetes, si actualmente tiene prediabetes o si padece cualquiera de los dos tipos de diabetes.\n",
        "*   PhysActivity : indica si la persona realiza algún tipo de actividad física en su rutina diaria.\n",
        "*   Fruits : indica si la persona consume 1 o más fruta(s) al día.\n",
        "*   Veggies : indica si la persona consume 1 o más verdura(s) diariamente.\n",
        "*   HvyAlcoholConsump : indica si la persona consume más de 14 bebidas a la semana.\n",
        "*   AnyHealthcare : indica si la persona tiene algún tipo de seguro médico.\n",
        "*   NoDocbcCost : indica si la persona quiso visitar a un médico en el último año pero no pudo debido al coste.\n",
        "*   GenHlth : indica la respuesta de la persona sobre su estado de salud general, de 1 (excelente) a 5 (mala).\n",
        "*   Menthlth : indica el número de días, en los últimos 30 días, que la persona tuvo mala salud mental.\n",
        "*   PhysHlth : indica el número de días, en los últimos 30 días, que la persona ha tenido mala salud física.\n",
        "*   DiffWalk : indica si la persona tiene dificultades para caminar o subir escaleras.\n",
        "*   Sex : indica el sexo de la persona, siendo 0 mujer y 1 hombre.\n",
        "*   Age : indica la clase de edad de la persona, donde 1 es de 18 a 24 años hasta 13 que es de 80 años o más, cada intervalo tiene un incremento de 5 años.\n",
        "*   Education : indica el año de estudios más alto completado, siendo 0 no haber asistido nunca o haber asistido sólo al jardín de infancia y 6 haber asistido a 4 años de universidad o más.\n",
        "*   Income : indica los ingresos totales del hogar, desde 1 (al menos 10.000) hasta 6 (más de 75.000 $).\n",
        "\n",
        "El caso de estudio al que nos enfrentamos es el de una aseguradora médica que pretende predecir si un cliente puede padecer riesgo de infarto cardíaco únicamente en base a los datos que da en la primera entrevista, por tanto la variable objetivo se trata de la posibilidad de sufrir dicho infarto.\n",
        "\n",
        "Cabe destacar que se trata de un dataset desbalanceado dado que si comprobamos el número de ocurrencias de los valores de la variable HeartDiseaseorAttack podemos observar que se distribuyen del siguiente modo: (0.0 - 229787) & (1.0 - 23893)"
      ],
      "metadata": {
        "id": "FlVPqWLIgGmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the DataFrame structure\n",
        "print(\"DataFrame Structure:\")\n",
        "print(data.head())\n",
        "\n",
        "# 1. Data types of each column\n",
        "print(\"1. Data Types:\")\n",
        "print(data.dtypes)\n",
        "\n",
        "# 2. Column labels\n",
        "print(\"\\n2. Columns:\")\n",
        "print(data.columns)\n",
        "\n",
        "# 3. Dimensions of the DataFrame\n",
        "print(\"\\n3. Shape:\")\n",
        "print(data.shape)\n",
        "\n",
        "# 4. Index (row labels) of the DataFrame\n",
        "print(\"\\n4. Index:\")\n",
        "print(data.index)\n",
        "\n",
        "# 5. Number of elements in the DataFrame\n",
        "print(\"\\n5. Size:\")\n",
        "print(data.size)\n",
        "\n",
        "# 6. Basic information about DataFrame structure\n",
        "print(\"\\n6. Basic Information about DataFrame:\")\n",
        "print(data.info())\n",
        "\n",
        "# 7. Summary statistics for numerical columns\n",
        "print(\"\\n7. Summary Statistics for Numerical Columns:\")\n",
        "print(data.describe())\n",
        "\n",
        "# 8. Imbalance in the target variable\n",
        "print(\"\\n8. Checking for imbalanced target variable:\")\n",
        "print(data['HeartDiseaseorAttack'].value_counts())\n",
        "\n",
        "# 9. Missing values\n",
        "print(\"\\n9. Checking for Missing Values:\")\n",
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1ENjEAwoqSk",
        "outputId": "b603bb5d-fc3c-4dc4-c4c9-ea4da739854f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Structure:\n",
            "   HeartDiseaseorAttack  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
            "0                   0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
            "1                   0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
            "2                   0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
            "3                   0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
            "4                   0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
            "\n",
            "   Diabetes  PhysActivity  Fruits  ...  AnyHealthcare  NoDocbcCost  GenHlth  \\\n",
            "0       0.0           0.0     0.0  ...            1.0          0.0      5.0   \n",
            "1       0.0           1.0     0.0  ...            0.0          1.0      3.0   \n",
            "2       0.0           0.0     1.0  ...            1.0          1.0      5.0   \n",
            "3       0.0           1.0     1.0  ...            1.0          0.0      2.0   \n",
            "4       0.0           1.0     1.0  ...            1.0          0.0      2.0   \n",
            "\n",
            "   MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  Income  \n",
            "0      18.0      15.0       1.0  0.0   9.0        4.0     3.0  \n",
            "1       0.0       0.0       0.0  0.0   7.0        6.0     1.0  \n",
            "2      30.0      30.0       1.0  0.0   9.0        4.0     8.0  \n",
            "3       0.0       0.0       0.0  0.0  11.0        3.0     6.0  \n",
            "4       3.0       0.0       0.0  0.0  11.0        5.0     4.0  \n",
            "\n",
            "[5 rows x 22 columns]\n",
            "1. Data Types:\n",
            "HeartDiseaseorAttack    float64\n",
            "HighBP                  float64\n",
            "HighChol                float64\n",
            "CholCheck               float64\n",
            "BMI                     float64\n",
            "Smoker                  float64\n",
            "Stroke                  float64\n",
            "Diabetes                float64\n",
            "PhysActivity            float64\n",
            "Fruits                  float64\n",
            "Veggies                 float64\n",
            "HvyAlcoholConsump       float64\n",
            "AnyHealthcare           float64\n",
            "NoDocbcCost             float64\n",
            "GenHlth                 float64\n",
            "MentHlth                float64\n",
            "PhysHlth                float64\n",
            "DiffWalk                float64\n",
            "Sex                     float64\n",
            "Age                     float64\n",
            "Education               float64\n",
            "Income                  float64\n",
            "dtype: object\n",
            "\n",
            "2. Columns:\n",
            "Index(['HeartDiseaseorAttack', 'HighBP', 'HighChol', 'CholCheck', 'BMI',\n",
            "       'Smoker', 'Stroke', 'Diabetes', 'PhysActivity', 'Fruits', 'Veggies',\n",
            "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
            "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
            "       'Income'],\n",
            "      dtype='object')\n",
            "\n",
            "3. Shape:\n",
            "(253680, 22)\n",
            "\n",
            "4. Index:\n",
            "RangeIndex(start=0, stop=253680, step=1)\n",
            "\n",
            "5. Size:\n",
            "5580960\n",
            "\n",
            "6. Basic Information about DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 253680 entries, 0 to 253679\n",
            "Data columns (total 22 columns):\n",
            " #   Column                Non-Null Count   Dtype  \n",
            "---  ------                --------------   -----  \n",
            " 0   HeartDiseaseorAttack  253680 non-null  float64\n",
            " 1   HighBP                253680 non-null  float64\n",
            " 2   HighChol              253680 non-null  float64\n",
            " 3   CholCheck             253680 non-null  float64\n",
            " 4   BMI                   253680 non-null  float64\n",
            " 5   Smoker                253680 non-null  float64\n",
            " 6   Stroke                253680 non-null  float64\n",
            " 7   Diabetes              253680 non-null  float64\n",
            " 8   PhysActivity          253680 non-null  float64\n",
            " 9   Fruits                253680 non-null  float64\n",
            " 10  Veggies               253680 non-null  float64\n",
            " 11  HvyAlcoholConsump     253680 non-null  float64\n",
            " 12  AnyHealthcare         253680 non-null  float64\n",
            " 13  NoDocbcCost           253680 non-null  float64\n",
            " 14  GenHlth               253680 non-null  float64\n",
            " 15  MentHlth              253680 non-null  float64\n",
            " 16  PhysHlth              253680 non-null  float64\n",
            " 17  DiffWalk              253680 non-null  float64\n",
            " 18  Sex                   253680 non-null  float64\n",
            " 19  Age                   253680 non-null  float64\n",
            " 20  Education             253680 non-null  float64\n",
            " 21  Income                253680 non-null  float64\n",
            "dtypes: float64(22)\n",
            "memory usage: 42.6 MB\n",
            "None\n",
            "\n",
            "7. Summary Statistics for Numerical Columns:\n",
            "       HeartDiseaseorAttack         HighBP       HighChol      CholCheck  \\\n",
            "count         253680.000000  253680.000000  253680.000000  253680.000000   \n",
            "mean               0.094186       0.429001       0.424121       0.962670   \n",
            "std                0.292087       0.494934       0.494210       0.189571   \n",
            "min                0.000000       0.000000       0.000000       0.000000   \n",
            "25%                0.000000       0.000000       0.000000       1.000000   \n",
            "50%                0.000000       0.000000       0.000000       1.000000   \n",
            "75%                0.000000       1.000000       1.000000       1.000000   \n",
            "max                1.000000       1.000000       1.000000       1.000000   \n",
            "\n",
            "                 BMI         Smoker         Stroke       Diabetes  \\\n",
            "count  253680.000000  253680.000000  253680.000000  253680.000000   \n",
            "mean       28.382364       0.443169       0.040571       0.296921   \n",
            "std         6.608694       0.496761       0.197294       0.698160   \n",
            "min        12.000000       0.000000       0.000000       0.000000   \n",
            "25%        24.000000       0.000000       0.000000       0.000000   \n",
            "50%        27.000000       0.000000       0.000000       0.000000   \n",
            "75%        31.000000       1.000000       0.000000       0.000000   \n",
            "max        98.000000       1.000000       1.000000       2.000000   \n",
            "\n",
            "        PhysActivity         Fruits  ...  AnyHealthcare    NoDocbcCost  \\\n",
            "count  253680.000000  253680.000000  ...  253680.000000  253680.000000   \n",
            "mean        0.756544       0.634256  ...       0.951053       0.084177   \n",
            "std         0.429169       0.481639  ...       0.215759       0.277654   \n",
            "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
            "25%         1.000000       0.000000  ...       1.000000       0.000000   \n",
            "50%         1.000000       1.000000  ...       1.000000       0.000000   \n",
            "75%         1.000000       1.000000  ...       1.000000       0.000000   \n",
            "max         1.000000       1.000000  ...       1.000000       1.000000   \n",
            "\n",
            "             GenHlth       MentHlth       PhysHlth       DiffWalk  \\\n",
            "count  253680.000000  253680.000000  253680.000000  253680.000000   \n",
            "mean        2.511392       3.184772       4.242081       0.168224   \n",
            "std         1.068477       7.412847       8.717951       0.374066   \n",
            "min         1.000000       0.000000       0.000000       0.000000   \n",
            "25%         2.000000       0.000000       0.000000       0.000000   \n",
            "50%         2.000000       0.000000       0.000000       0.000000   \n",
            "75%         3.000000       2.000000       3.000000       0.000000   \n",
            "max         5.000000      30.000000      30.000000       1.000000   \n",
            "\n",
            "                 Sex            Age      Education         Income  \n",
            "count  253680.000000  253680.000000  253680.000000  253680.000000  \n",
            "mean        0.440342       8.032119       5.050434       6.053875  \n",
            "std         0.496429       3.054220       0.985774       2.071148  \n",
            "min         0.000000       1.000000       1.000000       1.000000  \n",
            "25%         0.000000       6.000000       4.000000       5.000000  \n",
            "50%         0.000000       8.000000       5.000000       7.000000  \n",
            "75%         1.000000      10.000000       6.000000       8.000000  \n",
            "max         1.000000      13.000000       6.000000       8.000000  \n",
            "\n",
            "[8 rows x 22 columns]\n",
            "\n",
            "8. Checking for imbalanced target variable:\n",
            "0.0    229787\n",
            "1.0     23893\n",
            "Name: HeartDiseaseorAttack, dtype: int64\n",
            "\n",
            "9. Checking for Missing Values:\n",
            "HeartDiseaseorAttack    0\n",
            "HighBP                  0\n",
            "HighChol                0\n",
            "CholCheck               0\n",
            "BMI                     0\n",
            "Smoker                  0\n",
            "Stroke                  0\n",
            "Diabetes                0\n",
            "PhysActivity            0\n",
            "Fruits                  0\n",
            "Veggies                 0\n",
            "HvyAlcoholConsump       0\n",
            "AnyHealthcare           0\n",
            "NoDocbcCost             0\n",
            "GenHlth                 0\n",
            "MentHlth                0\n",
            "PhysHlth                0\n",
            "DiffWalk                0\n",
            "Sex                     0\n",
            "Age                     0\n",
            "Education               0\n",
            "Income                  0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Preparación del Dataset\n",
        "\n",
        "En este caso las variables categóricas ya han sido codificadas y no encontramos valores nulos que imputar, por lo que directamente procederemos a separar la variable objetivo del resto de predictores."
      ],
      "metadata": {
        "id": "_fQ_yj7VipRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target variable\n",
        "\n",
        "x = data.drop(columns = ['HeartDiseaseorAttack'], axis=1)\n",
        "y = data['HeartDiseaseorAttack']"
      ],
      "metadata": {
        "id": "r7HLQKZ3quC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Implementación de Cross-Validation\n",
        "Mediante técnicas de cross-validation dividiremos el dataset en 5 subconjuntos, en cada iteración una porción distinta seran los datos que usaremos para test mientras que las demás se utilizarán para entrenamiento, de este modo tendremos para cada iteración un 80% de datos de entrenamiento y un 20% de datos para test.\n",
        "\n",
        "En cuanto a la técnica de cross-validation seleccionada, debido a que se trata de un dataset con clases desbalanceadas he optado por utilizar Stratified k-fold pues permite dividir el dataset en conjuntos de test y entrenamiento respetando los ratios de las clases desbalanceadas."
      ],
      "metadata": {
        "id": "K-sI6Ar3i6gd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Create instance of StratifiedKFold technique for 5 subsets\n",
        "skf = StratifiedKFold(n_splits=5)"
      ],
      "metadata": {
        "id": "nWprUiHRoX53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Entrenamiento del Modelo\n",
        "Dado que se trata de un problema de clasificación he probado con los algoritmos RandomForestClassifier, ExtraTreesClassifier, DecisionTreeClassifier, GradientBoostingClassifier y AdaBoostClassifier.\n",
        "\n",
        "Pero el algoritmo con el que obtuve un mejor rendimiento fue LogisticRegression, este suceso puede tener una explicación en el hecho de que al tratarse de variables sanitarias generalmente suelen darse relaciones lineales, ej: si bebes alcohol y fumas tienes mayor riesgo de sufrir un infarto, mientras que si tienes un bajo nivel de colesterol y comes fruta se reduce."
      ],
      "metadata": {
        "id": "reRtbs4UllrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "for train, test in skf.split(x, y):\n",
        "\n",
        "  x_train, x_test = x.iloc[train], x.iloc[test]\n",
        "  y_train, y_test = y.iloc[train], y.iloc[test]\n",
        "\n",
        "  # Identify numerical columns\n",
        "  numerical_cols = x_train.select_dtypes(include=['float64']).columns\n",
        "\n",
        "  # Create transformer for numerical features\n",
        "  numerical_transformer = StandardScaler()\n",
        "\n",
        "  # Configure preprocessor to transform numerical variables\n",
        "  preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_cols)])\n",
        "\n",
        "  # Create pipeline to transform the data and train the model\n",
        "  model = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', LogisticRegression(random_state=42))])\n",
        "\n",
        "  # Apply the model to the training data\n",
        "  model.fit(x_train, y_train)\n",
        "\n",
        "  # Evaluate the model with the testing data\n",
        "  y_pred = model.predict(x_test)\n",
        "\n",
        "  print(\"Model Evaluation:\\n\")\n",
        "  print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuElIVn_lmWH",
        "outputId": "f353a1ca-2ab0-4fda-de70-9581f3267136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.99      0.95     45958\n",
            "         1.0       0.53      0.13      0.21      4778\n",
            "\n",
            "    accuracy                           0.91     50736\n",
            "   macro avg       0.73      0.56      0.58     50736\n",
            "weighted avg       0.88      0.91      0.88     50736\n",
            "\n",
            "Model Evaluation:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.99      0.95     45958\n",
            "         1.0       0.55      0.13      0.20      4778\n",
            "\n",
            "    accuracy                           0.91     50736\n",
            "   macro avg       0.73      0.56      0.58     50736\n",
            "weighted avg       0.88      0.91      0.88     50736\n",
            "\n",
            "Model Evaluation:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.99      0.95     45957\n",
            "         1.0       0.54      0.12      0.19      4779\n",
            "\n",
            "    accuracy                           0.91     50736\n",
            "   macro avg       0.73      0.55      0.57     50736\n",
            "weighted avg       0.88      0.91      0.88     50736\n",
            "\n",
            "Model Evaluation:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.99      0.95     45957\n",
            "         1.0       0.54      0.14      0.22      4779\n",
            "\n",
            "    accuracy                           0.91     50736\n",
            "   macro avg       0.73      0.56      0.58     50736\n",
            "weighted avg       0.88      0.91      0.88     50736\n",
            "\n",
            "Model Evaluation:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.99      0.95     45957\n",
            "         1.0       0.54      0.13      0.21      4779\n",
            "\n",
            "    accuracy                           0.91     50736\n",
            "   macro avg       0.73      0.56      0.58     50736\n",
            "weighted avg       0.88      0.91      0.88     50736\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Evaluación y Discusión:\n",
        "\n",
        "Para evaluar el modelo se han estudiado una serie de métricas que registran su comportamiento a la hora de predecir si el paciente sufrirá un infarto o no.\n",
        "\n",
        "En primer lugar explicaremos que representan estas métricas:\n",
        "\n",
        "* Precision (Precisión): indica la proporción de predicciones positivas correctas entre todas las predicciones positivas.\n",
        "\n",
        "* Recall (Exhaustividad o Sensibilidad): refleja la proporción de instancias positivas reales que el modelo ha logrado predecir correctamente.\n",
        "\n",
        "* F1-Score: media entre la precisión y la exhaustividad.\n",
        "\n",
        "* Accuracy (Exactitud): mide el porcentaje de predicciones correctas de todas las emitadas.\n",
        "\n",
        "* Macro Avg: media no ponderada de las métricas por clase.\n",
        "\n",
        "* Weighted Avg: media ponderada de las métricas por el número de instancias en cada clase.\n",
        "\n",
        "El modelo tiene un buen rendimiento en la clase mayoritaria (0.0) con alta precisión y recall, pero su rendimiento en la clase minoritaria (1.0) es limitado, como se refleja en un bajo recall y F1-score para esa clase, esto se debe a que, al tratarse de un dataset desbalanceado, cuenta con una cantidad de datos mucho mayor para una clase que para la otra, provocando que pueda predecir una gran diferencia de acierto una respecto a la otra.\n",
        "\n",
        "Gracias a la implementación de cross-validation podemos contar con un mayor número de métricas aplicadas a distintas combinaciones de subconjuntos dentro del dataset, lo cual nos aporta mayor seguridad a la hora de emitir juicios sobre sus valores, pues vemos que tienden a comportarse de un modo similar entre las distintas combinaciones.\n",
        "\n",
        "Además en este caso es especialmente importante elegir correctamente la técnica de cross-validation adecuada, ya que al tratarse de un dataset desbalanceado podríamos entrenar al modelo con una proporción de las clases que no reflejase verídicamente la realidad. Por ejemplo podríamos entrenar el modelo solo con datos de la clase 0 y que en la evaluación se enfrentase únicamente a datos de la clase 1, provocando que no haya podido estudiar este tipo de casos en la fase de entrenamiento y por tanto que fracase a la hora de ser evaluado."
      ],
      "metadata": {
        "id": "AQNxGlkwW0jt"
      }
    }
  ]
}