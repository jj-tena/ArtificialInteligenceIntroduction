{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TAREA 1 B"
      ],
      "metadata": {
        "id": "hPTSnKQIgKKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Selección de Dataset\n",
        "\n",
        "El dataset seleccionado se trata de Jena Climate Dataset: https://www.kaggle.com/datasets/mnassrib/jena-climate\n",
        "\n",
        "Este dataset contiene la información de 420551 fechas, para cada fecha se estudian una serie de características climatológicas en la Estación meteorológica del Instituto Max Planck de Biogeoquímica en Jena (Alemania)."
      ],
      "metadata": {
        "id": "rpL_TLcvgWYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/jena_climate.csv'\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "O11oUCQMgfna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Análisis Preliminar\n",
        "\n",
        "Para cada instante de tiempo se estudian las siguientes características:\n",
        "\n",
        "*   Date Time: fecha con la información del año, mes, dia, hora, minuto y segundo\n",
        "*   p (mbar): presión\n",
        "*   T (degC): temperatura\n",
        "*   Tpot (K): temperatura potencial\n",
        "*   Tdew (degC): temperatura de punto de condensación\n",
        "*   rh (%): humedad relativa\n",
        "*   VPmax (mbar): presión máxima de vapor\n",
        "*   VPact (mbar): presión de vapor real\n",
        "*   VPdef (mbar): déficit de presión de vapor\n",
        "*   sh (g/kg): humedad específica\n",
        "*   H2OC (mmol/mol): concentración de vapor de agua\n",
        "*   rho (g/m**3): densidad del aire\n",
        "*   wv (m/s): velocidad del viento\n",
        "*   max. wv (m/s): velocidad máxima del viento\n",
        "*   wd (deg): dirección del viento\n",
        "\n",
        "El caso de estudio al que nos enfrentamos es el de una empresa de agricultura que trabaja con cultivos de invernadero, por lo que el control de la temperatura en sus plantaciones requiere de un cuidado extremo.\n",
        "\n",
        "Dada esta situación, se nos pide desarrollar un modelo de inteligencia artificial que, en base a diversos parámetros meteorológicos, pueda predecir la temperatura que habrá en una fecha a fin de que la empresa pueda ajustar la temperatura interna del invernadero para ese momento."
      ],
      "metadata": {
        "id": "iWPi0IpSgqj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the DataFrame structure\n",
        "print(\"DataFrame Structure:\")\n",
        "print(data.head())\n",
        "\n",
        "# 1. Data types of each column\n",
        "print(\"1. Data Types:\")\n",
        "print(data.dtypes)\n",
        "\n",
        "# 2. Column labels\n",
        "print(\"\\n2. Columns:\")\n",
        "print(data.columns)\n",
        "\n",
        "# 3. Dimensions of the DataFrame\n",
        "print(\"\\n3. Shape:\")\n",
        "print(data.shape)\n",
        "\n",
        "# 4. Index (row labels) of the DataFrame\n",
        "print(\"\\n4. Index:\")\n",
        "print(data.index)\n",
        "\n",
        "# 5. Number of elements in the DataFrame\n",
        "print(\"\\n5. Size:\")\n",
        "print(data.size)\n",
        "\n",
        "# 6. Basic information about DataFrame structure\n",
        "print(\"\\n6. Basic Information about DataFrame:\")\n",
        "print(data.info())\n",
        "\n",
        "# 7. Summary statistics for numerical columns\n",
        "print(\"\\n7. Summary Statistics for Numerical Columns:\")\n",
        "print(data.describe())\n",
        "\n",
        "# 8. Missing values\n",
        "print(\"\\n9. Checking for Missing Values:\")\n",
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Jf7OP62guf2",
        "outputId": "62a126d7-0d0a-430f-8b6f-fd793659f6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Structure:\n",
            "             Date Time  p (mbar)  T (degC)  Tpot (K)  Tdew (degC)  rh (%)  \\\n",
            "0  01.01.2009 00:10:00    996.52     -8.02    265.40        -8.90    93.3   \n",
            "1  01.01.2009 00:20:00    996.57     -8.41    265.01        -9.28    93.4   \n",
            "2  01.01.2009 00:30:00    996.53     -8.51    264.91        -9.31    93.9   \n",
            "3  01.01.2009 00:40:00    996.51     -8.31    265.12        -9.07    94.2   \n",
            "4  01.01.2009 00:50:00    996.51     -8.27    265.15        -9.04    94.1   \n",
            "\n",
            "   VPmax (mbar)  VPact (mbar)  VPdef (mbar)  sh (g/kg)  H2OC (mmol/mol)  \\\n",
            "0          3.33          3.11          0.22       1.94             3.12   \n",
            "1          3.23          3.02          0.21       1.89             3.03   \n",
            "2          3.21          3.01          0.20       1.88             3.02   \n",
            "3          3.26          3.07          0.19       1.92             3.08   \n",
            "4          3.27          3.08          0.19       1.92             3.09   \n",
            "\n",
            "   rho (g/m**3)  wv (m/s)  max. wv (m/s)  wd (deg)  \n",
            "0       1307.75      1.03           1.75     152.3  \n",
            "1       1309.80      0.72           1.50     136.1  \n",
            "2       1310.24      0.19           0.63     171.6  \n",
            "3       1309.19      0.34           0.50     198.0  \n",
            "4       1309.00      0.32           0.63     214.3  \n",
            "1. Data Types:\n",
            "Date Time           object\n",
            "p (mbar)           float64\n",
            "T (degC)           float64\n",
            "Tpot (K)           float64\n",
            "Tdew (degC)        float64\n",
            "rh (%)             float64\n",
            "VPmax (mbar)       float64\n",
            "VPact (mbar)       float64\n",
            "VPdef (mbar)       float64\n",
            "sh (g/kg)          float64\n",
            "H2OC (mmol/mol)    float64\n",
            "rho (g/m**3)       float64\n",
            "wv (m/s)           float64\n",
            "max. wv (m/s)      float64\n",
            "wd (deg)           float64\n",
            "dtype: object\n",
            "\n",
            "2. Columns:\n",
            "Index(['Date Time', 'p (mbar)', 'T (degC)', 'Tpot (K)', 'Tdew (degC)',\n",
            "       'rh (%)', 'VPmax (mbar)', 'VPact (mbar)', 'VPdef (mbar)', 'sh (g/kg)',\n",
            "       'H2OC (mmol/mol)', 'rho (g/m**3)', 'wv (m/s)', 'max. wv (m/s)',\n",
            "       'wd (deg)'],\n",
            "      dtype='object')\n",
            "\n",
            "3. Shape:\n",
            "(184070, 15)\n",
            "\n",
            "4. Index:\n",
            "RangeIndex(start=0, stop=184070, step=1)\n",
            "\n",
            "5. Size:\n",
            "2761050\n",
            "\n",
            "6. Basic Information about DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 184070 entries, 0 to 184069\n",
            "Data columns (total 15 columns):\n",
            " #   Column           Non-Null Count   Dtype  \n",
            "---  ------           --------------   -----  \n",
            " 0   Date Time        184070 non-null  object \n",
            " 1   p (mbar)         184070 non-null  float64\n",
            " 2   T (degC)         184070 non-null  float64\n",
            " 3   Tpot (K)         184070 non-null  float64\n",
            " 4   Tdew (degC)      184070 non-null  float64\n",
            " 5   rh (%)           184070 non-null  float64\n",
            " 6   VPmax (mbar)     184070 non-null  float64\n",
            " 7   VPact (mbar)     184070 non-null  float64\n",
            " 8   VPdef (mbar)     184070 non-null  float64\n",
            " 9   sh (g/kg)        184070 non-null  float64\n",
            " 10  H2OC (mmol/mol)  184070 non-null  float64\n",
            " 11  rho (g/m**3)     184070 non-null  float64\n",
            " 12  wv (m/s)         184070 non-null  float64\n",
            " 13  max. wv (m/s)    184070 non-null  float64\n",
            " 14  wd (deg)         184070 non-null  float64\n",
            "dtypes: float64(14), object(1)\n",
            "memory usage: 21.1+ MB\n",
            "None\n",
            "\n",
            "7. Summary Statistics for Numerical Columns:\n",
            "            p (mbar)       T (degC)       Tpot (K)    Tdew (degC)  \\\n",
            "count  184070.000000  184070.000000  184070.000000  184070.000000   \n",
            "mean      988.871962       8.448712     282.517167       3.941040   \n",
            "std         8.693513       8.789573       8.896305       7.157956   \n",
            "min       913.600000     -23.010000     250.600000     -25.010000   \n",
            "25%       983.700000       2.440000     276.570000      -0.620000   \n",
            "50%       989.390000       8.610000     282.690000       4.360000   \n",
            "75%       994.590000      14.800000     288.880000       9.290000   \n",
            "max      1012.840000      34.920000     309.160000      20.360000   \n",
            "\n",
            "              rh (%)   VPmax (mbar)   VPact (mbar)   VPdef (mbar)  \\\n",
            "count  184070.000000  184070.000000  184070.000000  184070.000000   \n",
            "mean       75.823485      12.830262       8.982381       3.847803   \n",
            "std        16.653878       7.437135       4.115501       4.638972   \n",
            "min        12.950000       0.950000       0.790000       0.000000   \n",
            "25%        65.020000       7.280000       5.840000       0.790000   \n",
            "50%        79.300000      11.190000       8.340000       2.020000   \n",
            "75%        89.400000      16.860000      11.720000       5.100000   \n",
            "max       100.000000      56.040000      23.940000      39.500000   \n",
            "\n",
            "           sh (g/kg)  H2OC (mmol/mol)   rho (g/m**3)       wv (m/s)  \\\n",
            "count  184070.000000    184070.000000  184070.000000  184070.000000   \n",
            "mean        5.675950         9.087356    1220.348961       2.162796   \n",
            "std         2.612899         4.168551      42.454486       1.541796   \n",
            "min         0.500000         0.800000    1059.450000       0.000000   \n",
            "25%         3.680000         5.910000    1190.340000       1.020000   \n",
            "50%         5.270000         8.450000    1216.670000       1.820000   \n",
            "75%         7.410000        11.850000    1246.480000       2.900000   \n",
            "max        15.290000        24.350000    1393.540000      14.630000   \n",
            "\n",
            "       max. wv (m/s)       wd (deg)  \n",
            "count  184070.000000  184070.000000  \n",
            "mean        3.585594     175.706256  \n",
            "std         2.335044      86.878823  \n",
            "min         0.000000       0.000000  \n",
            "25%         1.820000     130.100000  \n",
            "50%         3.060000     198.900000  \n",
            "75%         4.810000     236.300000  \n",
            "max        23.500000     360.000000  \n",
            "\n",
            "9. Checking for Missing Values:\n",
            "Date Time          0\n",
            "p (mbar)           0\n",
            "T (degC)           0\n",
            "Tpot (K)           0\n",
            "Tdew (degC)        0\n",
            "rh (%)             0\n",
            "VPmax (mbar)       0\n",
            "VPact (mbar)       0\n",
            "VPdef (mbar)       0\n",
            "sh (g/kg)          0\n",
            "H2OC (mmol/mol)    0\n",
            "rho (g/m**3)       0\n",
            "wv (m/s)           0\n",
            "max. wv (m/s)      0\n",
            "wd (deg)           0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Preparación del Dataset\n",
        "\n",
        "En este caso de estudio no existen variables categóricas y no encontramos valores nulos que imputar.\n",
        "\n",
        "Solo sería necesario transformar la columna \"Date Time\" a un tipo más apropiado como datetime64 en lugar de float64."
      ],
      "metadata": {
        "id": "6FnkBmSegxKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Date Time column type from float64 to datetime64\n",
        "\n",
        "data['Date Time'] = pd.to_datetime(data['Date Time'], format = \"%d.%m.%Y %H:%M:%S\")\n",
        "\n",
        "# Separate features and target variable\n",
        "\n",
        "x = data.drop(columns = ['T (degC)'], axis=1)\n",
        "\n",
        "y = data['T (degC)']"
      ],
      "metadata": {
        "id": "0-gIJdHJg0PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Implementación de Cross-Validation\n",
        "Mediante técnicas de cross-validation realizaremos 5 evaluaciones de la capacidad de predicción que tiene nuestro modelo, para este propósito he decidido utilizar TimeSeriesSplit como técnica de cross-validation, esta técnica está específicamente diseñada para datasets con series temporales debido a que respeta la estructura temporal de los datos.\n",
        "\n",
        "Para ello al dividir los conjuntos asegura que el conjunto de test siempre se encuentre después de los conjuntos de entrenamiento, ya que los datos que el modelo pretende predecir siempre serán posteriores respecto a aquellos para los que el modelo ya cuenta con información previa. Evitando de este modo la aparición de data leakage al impedir que se entrene con información del futuro."
      ],
      "metadata": {
        "id": "zaHK0Wp9g-Mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "# Create instance of TimeSeriesSplit technique for 5 subsets\n",
        "tscv = TimeSeriesSplit(n_splits=5)"
      ],
      "metadata": {
        "id": "dEx5akyXg_9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Entrenamiento del Modelo\n",
        "\n",
        "Respecto a la elección del algoritmo para entrenar el modelo, teniendo en cuenta que se trata de un problema de regresión, he decidido apostar por utilizar LinearRegression debido a que suele darse una relación lineal entre variables climatológicas, ej: a mayor frío se da mayor cantidad de precipitaciones."
      ],
      "metadata": {
        "id": "UVVBLGXVhDQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "for train, test in tscv.split(x, y):\n",
        "\n",
        "  x_train, x_test = x.iloc[train], x.iloc[test]\n",
        "  y_train, y_test = y.iloc[train], y.iloc[test]\n",
        "\n",
        "  # Identify numerical columns\n",
        "  numerical_cols = x_train.select_dtypes(include=['float64']).columns\n",
        "\n",
        "  # Create transformer for numerical features\n",
        "  numerical_transformer = StandardScaler()\n",
        "\n",
        "  # Configure preprocessor to transform numerical variables\n",
        "  preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_cols)])\n",
        "\n",
        "  # Create pipeline to transform the data and train the model\n",
        "  model = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', LinearRegression())])\n",
        "\n",
        "  # Apply the model to the training data\n",
        "  model.fit(x_train, y_train)\n",
        "\n",
        "  # Evaluate the model with the testing data\n",
        "  y_pred = model.predict(x_test)\n",
        "\n",
        "  print(\"Model Evaluation:\")\n",
        "  mae = mean_absolute_error(y_test, y_pred)\n",
        "  print(f'MAE: {mae}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wilm_adkhEfj",
        "outputId": "2d8767a9-15b8-4f2e-f389-e3d9b8827013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation:\n",
            "MAE: 0.00834462345115233\n",
            "\n",
            "Model Evaluation:\n",
            "MAE: 0.007049643768562205\n",
            "\n",
            "Model Evaluation:\n",
            "MAE: 0.007026506075041364\n",
            "\n",
            "Model Evaluation:\n",
            "MAE: 0.006746114616356486\n",
            "\n",
            "Model Evaluation:\n",
            "MAE: 0.008316091267780783\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Evaluación y Discusión:\n",
        "\n",
        "Para la evaluación de métricas del modelo optaré por utilizar mean_absolute_error, que permite cuantificar el error promedio absoluto entre las predicciones y los valores reales.\n",
        "\n",
        "Podemos observar que a lo largo de todas las iteraciones se obtiene un error promedio absoluto extremadamente bajo, lo cual es garantía de que el modelo realiza predicciones precisas, es robusto y generaliza correctamente a datos no vistos.\n",
        "\n",
        "La implementación de cross-validation nos aporta una mayor confianza a la hora de emitir nuestros resultados, pues partiendo de un mismo dataset podemos obtener tantas evaluaciones como deseemos de nuestro modelo, ayudándonos a observar como las evaluaciones muestran una tendencia similar entre las distintas iteraciones.\n",
        "\n",
        "Debido a que el caso que nos ocupa es un problema de series temporales, si eligiésemos incorrectamente la técnica de cross-validation podríamos tener un problema de data leakage, puesto que podríamos entrenar con datos de fechas futuras el modelo e intentar predecir casos de fechas pasadas."
      ],
      "metadata": {
        "id": "EVbCIbAfc1kR"
      }
    }
  ]
}